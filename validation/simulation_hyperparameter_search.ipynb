{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ac3a6e-c66e-429f-87e7-ba1a556a9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import jax\n",
    "import jax.random as jr\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# from data.create_sim_data import *\n",
    "import data.template_causl_simulations as causl_py\n",
    "from data.run_all_simulations import plot_simulation_results\n",
    "import data.hyperparam_and_bootstrapping as hb\n",
    "from frugal_flows.causal_flows import independent_continuous_marginal_flow, get_independent_quantiles, train_frugal_flow\n",
    "from frugal_flows.bijections import UnivariateNormalCDF\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import SignatureTranslatedAnonymousPackage\n",
    "\n",
    "# Activate automatic conversion of rpy2 objects to pandas objects\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Import the R library causl\n",
    "try:\n",
    "    causl = importr('causl')\n",
    "except Exception as e:\n",
    "    package_names = ('causl')\n",
    "    utils.install_packages(StrVector(package_names))\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "hyperparams_dict = {\n",
    "    'learning_rate': 5e-3,\n",
    "    'RQS_knots': 8,\n",
    "    'flow_layers': 5,\n",
    "    'nn_width': 50,\n",
    "    'nn_depth': 4,    \n",
    "    'max_patience': 50,\n",
    "    'max_epochs': 10000\n",
    "}\n",
    "\n",
    "NUM_ITER = 10\n",
    "TRUE_PARAMS = {'ate': 1, 'const': 1, 'scale': 1}\n",
    "CAUSAL_PARAMS = [1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda393d3-575b-4f8d-93cd-97ffeefe858b",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "997c9403-0b33-4fac-a49f-ade847d5bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = causl_py.generate_gaussian_samples(N=1000, causal_params=[1,1], seed=0)\n",
    "Z_cont = data.get('Z_cont')\n",
    "X = data.get('X')\n",
    "Y = data.get('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f182bf-0c74-4041-83a4-6bb0a87637a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb760311-6306-4b96-af49-103b510dd318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7852d-4174-4d4b-bfee-1bb3d5c53907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87571c05-d982-4a72-a78c-e7c9ba82d246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "308edee0-1dfc-4bc5-8b28-d81569f7c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter ranges\n",
    "param_grid = {\n",
    "    'RQS_knots': [4, 6, 8],\n",
    "    'flow_layers': [4, 6, 8],\n",
    "    'nn_width': [20, 40, 60],\n",
    "    'nn_depth': [4, 6, 8],\n",
    "    'learning_rate': [3e-3, 5e-3],\n",
    "    'batch_size': [1000],\n",
    "    'max_patience': [50],\n",
    "    'max_epochs': [10000]\n",
    "}\n",
    "\n",
    "param_combinations = hb.generate_param_combinations(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2362512-5e81-4604-b232-3fe6a0d5c514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████▌                                                                                     | 1096/10000 [00:49<06:40, 22.21it/s, train=-0.1539257789469866, val=0.2261695015260868 (Max patience reached)]\n",
      "  7%|██████▊                                                                                         | 711/10000 [00:25<05:37, 27.54it/s, train=-0.13549111643113435, val=0.5551765969044515 (Max patience reached)]\n",
      " 14%|████████████▋                                                                                 | 1351/10000 [01:09<07:25, 19.42it/s, train=-0.34658835963764434, val=0.23451815353378067 (Max patience reached)]\n",
      " 22%|████████████████████▋                                                                          | 2182/10000 [02:36<09:21, 13.93it/s, train=-1.7833379680170227, val=-0.8207068324662511 (Max patience reached)]\n",
      " 22%|█████████████████████                                                                          | 2213/10000 [02:46<09:46, 13.28it/s, train=-0.9893547998694051, val=-0.8080613674279542 (Max patience reached)]\n",
      "  9%|████████▋                                                                                       | 911/10000 [00:40<06:46, 22.34it/s, train=-0.3321104782168916, val=0.11180469516132284 (Max patience reached)]\n",
      "  9%|████████▉                                                                                      | 940/10000 [00:41<06:38, 22.73it/s, train=-0.09834188098141056, val=0.35228275477732474 (Max patience reached)]\n",
      "  7%|██████▌                                                                                        | 685/10000 [00:27<06:07, 25.33it/s, train=-0.28563004621292887, val=0.49338161336655734 (Max patience reached)]\n",
      " 10%|█████████▌                                                                                      | 990/10000 [00:50<07:38, 19.64it/s, train=-0.11237836932172572, val=0.7442877797031475 (Max patience reached)]\n",
      "  5%|████▍                                                                                             | 455/10000 [00:17<06:11, 25.69it/s, train=0.4216959151880156, val=0.7265736273184381 (Max patience reached)]\n",
      "  9%|████████▊                                                                                        | 912/10000 [00:44<07:27, 20.31it/s, train=0.008216668516006637, val=0.916322039072595 (Max patience reached)]\n",
      " 11%|██████████▍                                                                                   | 1107/10000 [01:01<08:14, 17.98it/s, train=-0.9447876779125991, val=-0.20409419077386198 (Max patience reached)]\n",
      "  7%|██████▌                                                                                          | 679/10000 [00:28<06:35, 23.58it/s, train=0.24908081425019193, val=1.0969799087375212 (Max patience reached)]\n",
      "  8%|███████▌                                                                                         | 780/10000 [00:35<06:57, 22.10it/s, train=-0.4416698644072463, val=0.7887053066356814 (Max patience reached)]\n",
      "  8%|███████▍                                                                                         | 773/10000 [00:37<07:31, 20.46it/s, train=0.24952785829226118, val=0.7133345470592868 (Max patience reached)]\n",
      " 10%|█████████▊                                                                                      | 1018/10000 [00:53<07:56, 18.87it/s, train=-0.8288577286131751, val=0.4814171413217937 (Max patience reached)]\n",
      "  9%|████████▍                                                                                        | 870/10000 [00:51<09:03, 16.80it/s, train=-0.0917795932070166, val=0.8118868714967192 (Max patience reached)]\n",
      " 10%|█████████▉                                                                                     | 1045/10000 [01:02<08:57, 16.67it/s, train=-0.7295472500204195, val=0.15691945145583155 (Max patience reached)]\n",
      "  8%|███████▋                                                                                         | 795/10000 [00:35<06:51, 22.37it/s, train=0.16366865700710825, val=0.8419437834720338 (Max patience reached)]\n",
      "  6%|█████▋                                                                                         | 596/10000 [00:24<06:29, 24.13it/s, train=-0.07388091503677577, val=0.43550848043878165 (Max patience reached)]\n",
      " 14%|█████████████▋                                                                                 | 1443/10000 [01:29<08:52, 16.06it/s, train=-0.3651110454852742, val=0.19698978742576143 (Max patience reached)]\n",
      " 15%|█████████████▊                                                                                 | 1451/10000 [01:36<09:30, 14.97it/s, train=-1.3970051704738216, val=-0.3616274148037548 (Max patience reached)]\n",
      " 12%|███████████▊                                                                                   | 1241/10000 [01:16<09:00, 16.22it/s, train=-0.10633996238575912, val=0.4618701085105994 (Max patience reached)]\n",
      " 17%|███████████████▉                                                                                | 1664/10000 [01:59<09:57, 13.94it/s, train=-1.618554772349668, val=-0.5973306368309331 (Max patience reached)]\n",
      "  9%|████████▊                                                                                       | 918/10000 [00:48<08:00, 18.91it/s, train=-0.23211051167331517, val=1.1401391139822206 (Max patience reached)]\n",
      "  6%|██████▏                                                                                          | 640/10000 [00:30<07:25, 21.02it/s, train=-0.4407057884124305, val=0.6148941311302806 (Max patience reached)]\n",
      "  9%|████████▊                                                                                       | 923/10000 [00:52<08:41, 17.42it/s, train=-0.10735315376043575, val=0.5705133661034987 (Max patience reached)]\n",
      "  7%|██████▉                                                                                           | 705/10000 [00:43<09:30, 16.31it/s, train=-0.4453636511605238, val=0.563342093394802 (Max patience reached)]\n",
      "  9%|████████▎                                                                                      | 876/10000 [00:53<09:14, 16.47it/s, train=-0.031791311261610465, val=1.2439453365893491 (Max patience reached)]\n",
      "  7%|███████                                                                                        | 745/10000 [00:43<09:02, 17.07it/s, train=-0.39915654807909917, val=0.38179709280509694 (Max patience reached)]\n",
      "  8%|███████▉                                                                                         | 819/10000 [00:45<08:28, 18.04it/s, train=-0.18305450880593863, val=1.669853906432675 (Max patience reached)]\n",
      "  6%|█████▌                                                                                           | 572/10000 [00:29<08:05, 19.43it/s, train=-0.4355678812601335, val=0.9456239910025613 (Max patience reached)]\n",
      "  8%|███████▊                                                                                        | 813/10000 [00:49<09:22, 16.34it/s, train=-0.14906894125569836, val=0.4968703669853828 (Max patience reached)]\n",
      "  8%|███████▊                                                                                         | 799/10000 [00:50<09:37, 15.94it/s, train=-0.7135008554604989, val=0.7816539723205276 (Max patience reached)]\n",
      " 10%|█████████▏                                                                                      | 957/10000 [01:07<10:40, 14.11it/s, train=-0.21959979702268487, val=0.5680799508377505 (Max patience reached)]\n",
      "  8%|███████▎                                                                                          | 752/10000 [00:49<10:14, 15.06it/s, train=-0.547942535309485, val=0.3748650008676599 (Max patience reached)]\n",
      "  9%|████████▍                                                                                       | 873/10000 [00:47<08:12, 18.53it/s, train=0.036191968950678936, val=0.6735889389687653 (Max patience reached)]\n",
      "  7%|███████▏                                                                                           | 721/10000 [00:36<07:53, 19.58it/s, train=-0.405209108349978, val=0.530385752360721 (Max patience reached)]\n",
      " 11%|██████████                                                                                     | 1057/10000 [01:05<09:11, 16.23it/s, train=-0.17396748514216048, val=0.6817364091476218 (Max patience reached)]\n",
      "  8%|████████▏                                                                                       | 850/10000 [00:47<08:34, 17.77it/s, train=-0.4571258405096294, val=0.22766127611226827 (Max patience reached)]\n",
      " 12%|███████████▎                                                                                  | 1201/10000 [01:19<09:42, 15.10it/s, train=-0.22228159886783166, val=0.40305878153526975 (Max patience reached)]\n",
      " 20%|███████████████████▍                                                                           | 2043/10000 [03:02<11:52, 11.18it/s, train=-1.7494740491051042, val=-1.2876837533042242 (Max patience reached)]\n",
      "  6%|█████▊                                                                                           | 595/10000 [00:32<08:28, 18.50it/s, train=0.19515340829671862, val=1.3540493262198712 (Max patience reached)]\n",
      "  6%|██████▏                                                                                         | 646/10000 [00:35<08:37, 18.09it/s, train=-0.29468034312861535, val=0.7168471095364501 (Max patience reached)]\n",
      " 11%|██████████▋                                                                                     | 1117/10000 [01:17<10:13, 14.48it/s, train=-0.4107614778695916, val=0.7021972883315395 (Max patience reached)]\n",
      "  6%|█████▋                                                                                          | 589/10000 [00:34<09:17, 16.87it/s, train=-0.12023848149549152, val=0.6681132579312523 (Max patience reached)]\n",
      " 11%|██████████▋                                                                                     | 1107/10000 [01:20<10:48, 13.72it/s, train=-0.2347144762810061, val=0.3709417197386739 (Max patience reached)]\n",
      "  6%|█████▋                                                                                          | 590/10000 [00:37<09:57, 15.74it/s, train=-0.03827635736507252, val=0.5235554130304324 (Max patience reached)]\n",
      " 10%|█████████▌                                                                                     | 1003/10000 [01:07<10:04, 14.89it/s, train=-0.26690770077521037, val=0.8600647040969177 (Max patience reached)]\n",
      "  6%|█████▉                                                                                             | 601/10000 [00:35<09:17, 16.84it/s, train=-0.565158687216326, val=1.023636620969054 (Max patience reached)]\n",
      "  7%|███████                                                                                          | 722/10000 [00:49<10:39, 14.51it/s, train=0.06356056877447701, val=1.1997182204849535 (Max patience reached)]\n",
      "  7%|██████▍                                                                                           | 652/10000 [00:44<10:38, 14.65it/s, train=-0.5132588621005522, val=1.282174611517738 (Max patience reached)]\n",
      "  8%|███████▎                                                                                          | 752/10000 [00:58<11:53, 12.95it/s, train=0.0799268285695327, val=0.7341420761939051 (Max patience reached)]\n",
      "  5%|████▊                                                                                            | 494/10000 [00:36<11:39, 13.59it/s, train=0.06663830284768606, val=0.8326475015311786 (Max patience reached)]\n",
      " 11%|██████████                                                                                      | 1053/10000 [00:47<06:44, 22.10it/s, train=-0.1911144656869295, val=0.8883387301374651 (Max patience reached)]\n",
      " 15%|██████████████                                                                                | 1498/10000 [01:27<08:15, 17.15it/s, train=-1.4484971264569868, val=-0.44130955263442906 (Max patience reached)]\n",
      " 13%|████████████▊                                                                                   | 1333/10000 [01:10<07:38, 18.92it/s, train=-0.3202083033524611, val=0.8634096132038798 (Max patience reached)]\n",
      " 15%|██████████████▍                                                                                | 1526/10000 [01:39<09:15, 15.27it/s, train=-1.3780224254362068, val=-0.6533419558390471 (Max patience reached)]\n",
      " 19%|██████████████████                                                                              | 1876/10000 [02:11<09:30, 14.23it/s, train=-0.513593533098748, val=0.09479502541101635 (Max patience reached)]\n",
      " 12%|███████████▌                                                                                    | 1207/10000 [01:04<07:49, 18.73it/s, train=-0.6751083884689709, val=-0.324804750809704 (Max patience reached)]\n",
      "  8%|███████▍                                                                                        | 780/10000 [00:35<06:55, 22.19it/s, train=0.037747361969057695, val=0.8037473396568622 (Max patience reached)]\n",
      "  8%|███████▉                                                                                         | 819/10000 [00:37<06:56, 22.02it/s, train=-0.5039453048479722, val=0.3088365949416373 (Max patience reached)]\n",
      " 13%|████████████▎                                                                                   | 1281/10000 [01:16<08:43, 16.66it/s, train=-0.5727056913882783, val=0.4855139214426902 (Max patience reached)]\n",
      "  6%|█████▎                                                                                          | 558/10000 [00:27<07:39, 20.55it/s, train=-0.08349154495380127, val=0.7474691149393514 (Max patience reached)]\n",
      " 13%|████████████                                                                                    | 1256/10000 [01:28<10:17, 14.16it/s, train=-0.2986316280444592, val=0.6984382909963338 (Max patience reached)]\n",
      "  7%|███████▏                                                                                          | 739/10000 [00:39<08:17, 18.61it/s, train=-0.367559633545514, val=0.6164433839063936 (Max patience reached)]\n",
      "  7%|██████▍                                                                                           | 652/10000 [00:32<07:41, 20.27it/s, train=0.2340698410311461, val=1.1724320125229322 (Max patience reached)]\n",
      "  6%|█████▋                                                                                          | 586/10000 [00:28<07:35, 20.65it/s, train=-0.23354673136286896, val=1.0279161837603048 (Max patience reached)]\n",
      "  9%|████████▎                                                                                       | 869/10000 [00:50<08:51, 17.17it/s, train=0.010484498573543086, val=0.9296119163834519 (Max patience reached)]\n",
      "  7%|███████▎                                                                                         | 749/10000 [00:42<08:42, 17.71it/s, train=-0.7327438785707668, val=0.3476693587582233 (Max patience reached)]\n",
      "  8%|███████▍                                                                                        | 774/10000 [00:47<09:21, 16.42it/s, train=0.048012523723904126, val=1.2408197538979062 (Max patience reached)]\n",
      " 10%|█████████▍                                                                                      | 977/10000 [01:04<09:51, 15.26it/s, train=-0.8253280349334999, val=0.39488712398345877 (Max patience reached)]\n",
      "  9%|████████▍                                                                                      | 892/10000 [00:47<08:09, 18.60it/s, train=-0.044404998023560106, val=0.8939459163212796 (Max patience reached)]\n",
      " 13%|████████████▋                                                                                    | 1309/10000 [01:25<09:25, 15.37it/s, train=-1.080881197759792, val=0.3859839901282536 (Max patience reached)]\n",
      " 10%|█████████▉                                                                                     | 1050/10000 [01:06<09:25, 15.83it/s, train=-0.00692104597863278, val=0.9233198075836652 (Max patience reached)]\n",
      "  9%|████████▋                                                                                       | 909/10000 [00:56<09:22, 16.15it/s, train=-0.6922792383505996, val=0.32777142709256746 (Max patience reached)]\n",
      " 12%|███████████▍                                                                                    | 1190/10000 [01:23<10:18, 14.24it/s, train=-0.3423835000257014, val=0.3492620554153465 (Max patience reached)]\n",
      "  7%|██████▌                                                                                         | 684/10000 [00:40<09:17, 16.70it/s, train=-0.09182297429113694, val=0.5502075744386492 (Max patience reached)]\n",
      "  6%|█████▌                                                                                            | 571/10000 [00:32<09:04, 17.31it/s, train=0.3830708552198386, val=1.3142721986609625 (Max patience reached)]\n",
      "  0%|                                                                                                                                                                                     | 0/10000 [00:00<?, ?it/s]2024-05-15 14:27:48.066138: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 2m31.406121s\n",
      "\n",
      "********************************\n",
      "[Compiling module jit___call__] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n",
      "  7%|███████                                                                                          | 726/10000 [03:40<46:50,  3.30it/s, train=-0.6064670580443556, val=0.6497531198939089 (Max patience reached)]\n",
      " 12%|███████████▎                                                                                    | 1180/10000 [01:34<11:45, 12.50it/s, train=-0.5632740664563125, val=0.6370124258237132 (Max patience reached)]\n",
      "  6%|█████▋                                                                                          | 595/10000 [00:36<09:30, 16.49it/s, train=-0.20769849459015108, val=0.7676000283363488 (Max patience reached)]\n",
      "  7%|███████▏                                                                                         | 736/10000 [00:49<10:25, 14.82it/s, train=0.03216170824378261, val=1.0080226201626188 (Max patience reached)]\n",
      " 10%|█████████▋                                                                                     | 1018/10000 [01:16<11:17, 13.25it/s, train=-0.9298863383572835, val=0.00952021904302845 (Max patience reached)]\n",
      "  8%|███████▊                                                                                        | 816/10000 [00:53<10:06, 15.13it/s, train=-0.09601217014318245, val=1.0675144355144877 (Max patience reached)]\n",
      "  5%|████▋                                                                                           | 482/10000 [00:28<09:28, 16.73it/s, train=-0.12378376485736695, val=1.3179306510641398 (Max patience reached)]\n",
      "  9%|█████████▏                                                                                        | 939/10000 [01:11<11:29, 13.15it/s, train=-0.293911190743519, val=1.1829451869067182 (Max patience reached)]\n",
      "  6%|██████                                                                                           | 629/10000 [00:44<10:55, 14.30it/s, train=-0.45034143498051743, val=1.235872287596028 (Max patience reached)]\n",
      "  8%|███████▎                                                                                        | 759/10000 [00:59<11:59, 12.84it/s, train=-0.06395998709234758, val=1.0403212980950505 (Max patience reached)]\n",
      "  7%|███████                                                                                         | 741/10000 [00:58<12:13, 12.63it/s, train=-0.4486054326881021, val=0.01556343046447889 (Max patience reached)]\n",
      "  7%|███████▏                                                                                          | 738/10000 [00:45<09:30, 16.24it/s, train=0.1670372582437794, val=0.6805294480401985 (Max patience reached)]\n",
      "  8%|███████▍                                                                                         | 761/10000 [00:48<09:53, 15.57it/s, train=-0.4784205677913089, val=0.5433282457849169 (Max patience reached)]\n",
      "  8%|████████                                                                                       | 850/10000 [00:56<10:03, 15.17it/s, train=-0.059005492521607604, val=0.8619410436585061 (Max patience reached)]\n",
      "  8%|████████                                                                                         | 834/10000 [00:55<10:08, 15.06it/s, train=-0.4912502849186187, val=0.7897361585716522 (Max patience reached)]\n",
      "  8%|███████▋                                                                                         | 793/10000 [00:53<10:20, 14.83it/s, train=0.09229528515036603, val=1.0965059996643463 (Max patience reached)]\n",
      "  8%|███████▎                                                                                       | 772/10000 [00:52<10:26, 14.72it/s, train=-0.28835525763274866, val=0.23299850512326012 (Max patience reached)]\n",
      " 11%|██████████▍                                                                                     | 1084/10000 [01:20<11:05, 13.40it/s, train=-0.7431182701165358, val=1.0513583054034756 (Max patience reached)]\n",
      "  1%|█▎                                                                                                                       | 112/10000 [00:08<12:29, 13.20it/s, train=2.3493018463735926, val=2.3602388347776877]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hyperparam_fits \u001b[38;5;241m=\u001b[39m \u001b[43mhb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_outcome_hyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_disc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_cont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mZ_cont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_combinations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_combinations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-danielmanela@gmail.com/My Drive/work/deep-copula-frugal/validation/../data/hyperparam_and_bootstrapping.py:97\u001b[0m, in \u001b[0;36mgaussian_outcome_hyperparameter_search\u001b[0;34m(X, Y, Z_disc, Z_cont, param_combinations, seed)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, param_set \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(param_combinations):\n\u001b[1;32m     96\u001b[0m     results \u001b[38;5;241m=\u001b[39m param_set\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 97\u001b[0m     fitted_flow \u001b[38;5;241m=\u001b[39m \u001b[43mcausl_py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrugal_fitting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_disc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mZ_disc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_cont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mZ_cont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrugal_flow_hyperparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     causal_margin \u001b[38;5;241m=\u001b[39m fitted_flow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcausal_margin\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[1;32m     99\u001b[0m     results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m causal_margin\u001b[38;5;241m.\u001b[39mate\n",
      "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-danielmanela@gmail.com/My Drive/work/deep-copula-frugal/validation/../data/template_causl_simulations.py:108\u001b[0m, in \u001b[0;36mfrugal_fitting\u001b[0;34m(X, Y, use_marginal_flow, Z_disc, Z_cont, seed, frugal_flow_hyperparams)\u001b[0m\n\u001b[1;32m    106\u001b[0m     uz_samples \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mvstack([uz_disc_samples, uz_cont_samples])\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Learn Frugal Flow\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m frugal_flow, losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_frugal_flow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubkeys\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mu_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muz_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfrugal_flow_hyperparams\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m causal_margin \u001b[38;5;241m=\u001b[39m frugal_flow\u001b[38;5;241m.\u001b[39mbijection\u001b[38;5;241m.\u001b[39mbijections[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mbijection\u001b[38;5;241m.\u001b[39mbijections[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrugal_flow\u001b[39m\u001b[38;5;124m'\u001b[39m: frugal_flow,\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m'\u001b[39m: losses,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muz_cont\u001b[39m\u001b[38;5;124m'\u001b[39m: uz_cont_samples\n\u001b[1;32m    122\u001b[0m }\n",
      "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-danielmanela@gmail.com/My Drive/work/deep-copula-frugal/validation/../frugal_flows/causal_flows.py:172\u001b[0m, in \u001b[0;36mtrain_frugal_flow\u001b[0;34m(key, y, u_z, optimizer, RQS_knots, nn_depth, nn_width, flow_layers, show_progress, learning_rate, max_epochs, max_patience, batch_size, condition, stop_grad_until_active)\u001b[0m\n\u001b[1;32m    169\u001b[0m key, subkey \u001b[38;5;241m=\u001b[39m jr\u001b[38;5;241m.\u001b[39msplit(key)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m frugal_flow, losses \u001b[38;5;241m=\u001b[39m \u001b[43mfit_to_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrugal_flow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_z\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_patience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frugal_flow, losses\n",
      "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-danielmanela@gmail.com/My Drive/work/deep-copula-frugal/flowjax/flowjax/train/data_fit.py:97\u001b[0m, in \u001b[0;36mfit_to_data\u001b[0;34m(key, dist, x, condition, loss_fn, max_epochs, max_patience, batch_size, val_prop, learning_rate, optimizer, return_best, show_progress)\u001b[0m\n\u001b[1;32m     93\u001b[0m losses \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[1;32m     95\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(max_epochs), disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress)\n\u001b[0;32m---> 97\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Shuffle data\u001b[39;49;00m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubkeys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mjr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermutation\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubkeys\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/deep-frugal/lib/python3.11/site-packages/tqdm/std.py:1191\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m dt \u001b[38;5;241m=\u001b[39m cur_t \u001b[38;5;241m-\u001b[39m last_print_t\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dt \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m mininterval \u001b[38;5;129;01mand\u001b[39;00m cur_t \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_start_t:\n\u001b[0;32m-> 1191\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_print_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1192\u001b[0m     last_print_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_print_n\n\u001b[1;32m   1193\u001b[0m     last_print_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_print_t\n",
      "File \u001b[0;32m~/micromamba/envs/deep-frugal/lib/python3.11/site-packages/tqdm/std.py:1242\u001b[0m, in \u001b[0;36mtqdm.update\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ema_dn(dn)\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ema_dt(dt)\n\u001b[0;32m-> 1242\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlock_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlock_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_miniters:\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;66;03m# If no `miniters` was specified, adjust automatically to the\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;66;03m# maximum iteration rate seen so far between two prints.\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;66;03m# e.g.: After running `tqdm.update(5)`, subsequent\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;66;03m# calls to `tqdm.update()` will only cause an update after\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;66;03m# at least 5 more iterations.\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxinterval \u001b[38;5;129;01mand\u001b[39;00m dt \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxinterval:\n",
      "File \u001b[0;32m~/micromamba/envs/deep-frugal/lib/python3.11/site-packages/tqdm/std.py:1347\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m-> 1347\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/micromamba/envs/deep-frugal/lib/python3.11/site-packages/tqdm/std.py:1495\u001b[0m, in \u001b[0;36mtqdm.display\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(pos)\n\u001b[0;32m-> 1495\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__str__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[1;32m   1497\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(\u001b[38;5;241m-\u001b[39mpos)\n",
      "File \u001b[0;32m~/micromamba/envs/deep-frugal/lib/python3.11/site-packages/tqdm/std.py:459\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.print_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_status\u001b[39m(s):\n\u001b[1;32m    458\u001b[0m     len_s \u001b[38;5;241m=\u001b[39m disp_len(s)\n\u001b[0;32m--> 459\u001b[0m     \u001b[43mfp_write\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlast_len\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlen_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     last_len[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m len_s\n",
      "File \u001b[0;32m~/micromamba/envs/deep-frugal/lib/python3.11/site-packages/tqdm/std.py:452\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.fp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfp_write\u001b[39m(s):\n\u001b[0;32m--> 452\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m     fp_flush()\n",
      "File \u001b[0;32m~/micromamba/envs/deep-frugal/lib/python3.11/site-packages/tqdm/utils.py:196\u001b[0m, in \u001b[0;36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n",
      "File \u001b[0;32m~/micromamba/envs/deep-frugal/lib/python3.11/site-packages/ipykernel/iostream.py:694\u001b[0m, in \u001b[0;36mOutStream.write\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
      "File \u001b[0;32m~/micromamba/envs/deep-frugal/lib/python3.11/site-packages/ipykernel/iostream.py:590\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_schedule_in_thread\u001b[39m():\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39mcall_later(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_interval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[0;32m--> 590\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_schedule_in_thread\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/deep-frugal/lib/python3.11/site-packages/ipykernel/iostream.py:267\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     f()\n",
      "File \u001b[0;32m~/micromamba/envs/deep-frugal/lib/python3.11/site-packages/zmq/sugar/socket.py:696\u001b[0m, in \u001b[0;36mSocket.send\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    689\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[1;32m    690\u001b[0m             data,\n\u001b[1;32m    691\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[1;32m    692\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    693\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[1;32m    694\u001b[0m         )\n\u001b[1;32m    695\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/micromamba/envs/deep-frugal/lib/python3.11/site-packages/zmq/backend/cython/checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparam_fits = hb.gaussian_outcome_hyperparameter_search(\n",
    "    X, Y, Z_disc=None, Z_cont=Z_cont, param_combinations=param_combinations, seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7825caa-cdad-4f69-99aa-b41b0d784adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RQS_knots</th>\n",
       "      <th>flow_layers</th>\n",
       "      <th>nn_width</th>\n",
       "      <th>nn_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>max_patience</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>ate</th>\n",
       "      <th>const</th>\n",
       "      <th>scale</th>\n",
       "      <th>min_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.7150669160365015</td>\n",
       "      <td>1.374007716934389</td>\n",
       "      <td>1.4217528496579643</td>\n",
       "      <td>-1.3260963361708087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8266724675551651</td>\n",
       "      <td>1.5860350125175438</td>\n",
       "      <td>2.29718594724751</td>\n",
       "      <td>-1.3028112910257834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0179928860883678</td>\n",
       "      <td>1.665140150428186</td>\n",
       "      <td>2.572571572273175</td>\n",
       "      <td>-0.6892003449425886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8571017907300323</td>\n",
       "      <td>1.7412041588663232</td>\n",
       "      <td>2.4900306210544714</td>\n",
       "      <td>-0.6708703916855526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.9446084566625047</td>\n",
       "      <td>1.5971757854820765</td>\n",
       "      <td>2.3495064545679925</td>\n",
       "      <td>-0.5243316967847134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.4900972867872</td>\n",
       "      <td>1.9371309025109238</td>\n",
       "      <td>2.862495278420609</td>\n",
       "      <td>-0.5242080519884562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.035237754176492</td>\n",
       "      <td>1.684316556302863</td>\n",
       "      <td>2.4932209816214552</td>\n",
       "      <td>-0.5143605829525498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.736149392203217</td>\n",
       "      <td>1.9078992491636033</td>\n",
       "      <td>2.872326192508355</td>\n",
       "      <td>-0.4606091843220257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>2.1145454335751657</td>\n",
       "      <td>2.2542805387658795</td>\n",
       "      <td>3.0904339231313105</td>\n",
       "      <td>-0.3695486533062358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.7178410146193837</td>\n",
       "      <td>1.9942493167948057</td>\n",
       "      <td>2.925035631203214</td>\n",
       "      <td>-0.3574400345667037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.910317934485012</td>\n",
       "      <td>2.2243246435427255</td>\n",
       "      <td>3.055854333717607</td>\n",
       "      <td>-0.32561498626659763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>2.5300636220676007</td>\n",
       "      <td>2.4262657018093323</td>\n",
       "      <td>3.1386571967774604</td>\n",
       "      <td>-0.27967169992875407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.6628966339739122</td>\n",
       "      <td>1.7780832021510726</td>\n",
       "      <td>2.8036403746406733</td>\n",
       "      <td>-0.25427107928011206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>2.575726760468766</td>\n",
       "      <td>2.5319814201601307</td>\n",
       "      <td>3.161538083870624</td>\n",
       "      <td>-0.15190729056707653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>2.1078581370232614</td>\n",
       "      <td>1.877770832202059</td>\n",
       "      <td>2.9499862941906234</td>\n",
       "      <td>-0.12667587122282606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>2.3017315420579068</td>\n",
       "      <td>2.541155605596309</td>\n",
       "      <td>3.1398018500146025</td>\n",
       "      <td>-0.06300421901227228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>2.2076735489019486</td>\n",
       "      <td>2.344330679097973</td>\n",
       "      <td>3.101975960996793</td>\n",
       "      <td>-0.0611600931885063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>2.379723364283866</td>\n",
       "      <td>2.338288122021272</td>\n",
       "      <td>3.106809372137166</td>\n",
       "      <td>-0.049834485542875645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>2.855572933548937</td>\n",
       "      <td>2.9296777211605</td>\n",
       "      <td>3.1612962847450756</td>\n",
       "      <td>-0.023199429621102413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>2.4714634329150815</td>\n",
       "      <td>2.4679280368573466</td>\n",
       "      <td>3.143997690413096</td>\n",
       "      <td>-0.007823643244174052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RQS_knots flow_layers nn_width nn_depth learning_rate batch_size  \\\n",
       "0         4           2       60        8         0.003       1000   \n",
       "0         4           2       35        2         0.003       1000   \n",
       "0         4           2       25        4         0.003       1000   \n",
       "0         4           2       45        6         0.003       1000   \n",
       "0         6           2       50        8         0.003       1000   \n",
       "0         6           2       25        4         0.003       1000   \n",
       "0         4           2       50        4         0.003       1000   \n",
       "0         8           2       25        4         0.003       1000   \n",
       "0         4           2       25        2         0.003       1000   \n",
       "0         4           2       45        8         0.003       1000   \n",
       "0         4           2       25        6         0.003       1000   \n",
       "0         8           2       60        4         0.003       1000   \n",
       "0         6           2       25        8         0.003       1000   \n",
       "0         4           2       50        6         0.003       1000   \n",
       "0         6           2       35        6         0.003       1000   \n",
       "0         4           4       25        6         0.003       1000   \n",
       "0         4           2       45        2         0.003       1000   \n",
       "0         8           2       50        6         0.003       1000   \n",
       "0         4           2       60        6         0.003       1000   \n",
       "0         4           4       50        8         0.003       1000   \n",
       "\n",
       "  max_patience max_epochs                 ate               const  \\\n",
       "0           50      10000  0.7150669160365015   1.374007716934389   \n",
       "0           50      10000  0.8266724675551651  1.5860350125175438   \n",
       "0           50      10000  1.0179928860883678   1.665140150428186   \n",
       "0           50      10000  0.8571017907300323  1.7412041588663232   \n",
       "0           50      10000  0.9446084566625047  1.5971757854820765   \n",
       "0           50      10000     1.4900972867872  1.9371309025109238   \n",
       "0           50      10000   1.035237754176492   1.684316556302863   \n",
       "0           50      10000   1.736149392203217  1.9078992491636033   \n",
       "0           50      10000  2.1145454335751657  2.2542805387658795   \n",
       "0           50      10000  1.7178410146193837  1.9942493167948057   \n",
       "0           50      10000   1.910317934485012  2.2243246435427255   \n",
       "0           50      10000  2.5300636220676007  2.4262657018093323   \n",
       "0           50      10000  1.6628966339739122  1.7780832021510726   \n",
       "0           50      10000   2.575726760468766  2.5319814201601307   \n",
       "0           50      10000  2.1078581370232614   1.877770832202059   \n",
       "0           50      10000  2.3017315420579068   2.541155605596309   \n",
       "0           50      10000  2.2076735489019486   2.344330679097973   \n",
       "0           50      10000   2.379723364283866   2.338288122021272   \n",
       "0           50      10000   2.855572933548937     2.9296777211605   \n",
       "0           50      10000  2.4714634329150815  2.4679280368573466   \n",
       "\n",
       "                scale               min_loss  \n",
       "0  1.4217528496579643    -1.3260963361708087  \n",
       "0    2.29718594724751    -1.3028112910257834  \n",
       "0   2.572571572273175    -0.6892003449425886  \n",
       "0  2.4900306210544714    -0.6708703916855526  \n",
       "0  2.3495064545679925    -0.5243316967847134  \n",
       "0   2.862495278420609    -0.5242080519884562  \n",
       "0  2.4932209816214552    -0.5143605829525498  \n",
       "0   2.872326192508355    -0.4606091843220257  \n",
       "0  3.0904339231313105    -0.3695486533062358  \n",
       "0   2.925035631203214    -0.3574400345667037  \n",
       "0   3.055854333717607   -0.32561498626659763  \n",
       "0  3.1386571967774604   -0.27967169992875407  \n",
       "0  2.8036403746406733   -0.25427107928011206  \n",
       "0   3.161538083870624   -0.15190729056707653  \n",
       "0  2.9499862941906234   -0.12667587122282606  \n",
       "0  3.1398018500146025   -0.06300421901227228  \n",
       "0   3.101975960996793    -0.0611600931885063  \n",
       "0   3.106809372137166  -0.049834485542875645  \n",
       "0  3.1612962847450756  -0.023199429621102413  \n",
       "0   3.143997690413096  -0.007823643244174052  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam_fits.sort_values('min_loss').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3b579f-8acd-4a8d-93ac-6879b87bd2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
