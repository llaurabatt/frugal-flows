{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671156ae-3e66-4997-85ba-b18bdfaec591",
   "metadata": {},
   "source": [
    "# Example Pipeline for e401k\n",
    "\n",
    "This notebook is a proof-of-concept for generating causal samples from external samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94fec690-e143-4b90-a218-f6652bdb2a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\")  # go to parent dir\n",
    "# sys.path.append(\"../data/analysis/\")  # go to parent dir\n",
    "\n",
    "import jax\n",
    "import jax.random as jr\n",
    "import jax.numpy as jnp\n",
    "# jnp.set_printoptions(precision=2)\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "from rpy2.robjects.packages import SignatureTranslatedAnonymousPackage\n",
    "\n",
    "from frugal_flows.causal_flows import independent_continuous_marginal_flow, get_independent_quantiles, train_frugal_flow\n",
    "from frugal_flows.sample_outcome import sample_outcome\n",
    "from frugal_flows.sample_marginals import from_quantiles_to_marginal_cont, from_quantiles_to_marginal_discr\n",
    "from frugal_flows.train_quantile_propensity_score import train_quantile_propensity_score\n",
    "from frugal_flows.bijections import UnivariateNormalCDF\n",
    "from frugal_flows.benchmarking import FrugalFlowModel\n",
    "from frugal_flows.sample_outcome import sample_outcome\n",
    "from frugal_flows.sample_marginals import from_quantiles_to_marginal_cont, from_quantiles_to_marginal_discr\n",
    "from frugal_flows.train_quantile_propensity_score import train_quantile_propensity_score\n",
    "import torch\n",
    "from benchmarking import compare_datasets\n",
    "\n",
    "\n",
    "import data.template_causl_simulations as causl_py\n",
    "import data.analysis.validationMethods as valMethods\n",
    "import wandb\n",
    "\n",
    "# Activate automatic conversion of rpy2 objects to pandas objects\n",
    "pandas2ri.activate()\n",
    "base = importr('base')\n",
    "utils = importr('utils')\n",
    "\n",
    "# Import the R library causl\n",
    "try:\n",
    "    causl = importr('causl')\n",
    "except Exception as e:\n",
    "    package_names = ('causl')\n",
    "    utils.install_packages(StrVector(package_names))\n",
    "\n",
    "seed = 0\n",
    "N = 2000\n",
    "B = 50\n",
    "sampling_size = 1000\n",
    "keys, *subkeys = jr.split(jr.PRNGKey(seed), 20)\n",
    "\n",
    "def clean_ate(value):\n",
    "    if isinstance(value, (list, tuple, np.ndarray)):\n",
    "        return np.mean(value)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a96658fe-6620-4cfa-8de7-c1e6bdff8930",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'e401k_rescaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Z_disc = jnp.array(e401k_filtered[disc_columns].values)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m Z_disc \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(e401k_filtered[disc_columns]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m---> 59\u001b[0m e401k_rescaled \u001b[38;5;241m=\u001b[39m \u001b[43me401k_rescaled\u001b[49m[\n\u001b[1;32m     60\u001b[0m     [standardised_outcome_col, treatment_col] \u001b[38;5;241m+\u001b[39m covariate_colnames\n\u001b[1;32m     61\u001b[0m ]\n\u001b[1;32m     63\u001b[0m true_ATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     64\u001b[0m benchmark_flow \u001b[38;5;241m=\u001b[39m FrugalFlowModel(Y\u001b[38;5;241m=\u001b[39mY, X\u001b[38;5;241m=\u001b[39mX, Z_disc\u001b[38;5;241m=\u001b[39mZ_disc, Z_cont\u001b[38;5;241m=\u001b[39mZ_cont, confounding_copula\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'e401k_rescaled' is not defined"
     ]
    }
   ],
   "source": [
    "marginal_hyperparam_dict = {\n",
    "    'learning_rate': 5e-4,\n",
    "    # 'learning_rate': 0.2,\n",
    "    'RQS_knots': 8,\n",
    "    'flow_layers': 3,\n",
    "    'nn_depth': 5,    \n",
    "    'nn_width': 10,\n",
    "    'max_patience': 100,\n",
    "    'max_epochs': 20000\n",
    "}\n",
    "hyperparam_dict = {\n",
    "    'learning_rate': 0.00261635,\n",
    "    'RQS_knots': 5,\n",
    "    'flow_layers': 2,\n",
    "    'nn_depth': 3,    \n",
    "    'nn_width': 34,\n",
    "    'max_patience': 100,\n",
    "    'max_epochs': 20000\n",
    "}\n",
    "causal_margin_hyperparams_dict = {\n",
    "    'RQS_knots': 4,\n",
    "    'flow_layers': 8,\n",
    "    'nn_depth': 10,    \n",
    "    'nn_width': 50,\n",
    "}\n",
    "seed=7\n",
    "\n",
    "# Load data\n",
    "e401k = pd.read_csv('../data/filtered_401k_data.csv')\n",
    "\n",
    "# Preprocess data\n",
    "outcome_col = 'net_tfa'\n",
    "treatment_col = 'e401'\n",
    "standardised_outcome_col = f'{outcome_col}_standardised'\n",
    "Y_control = e401k.loc[e401k[treatment_col]==0, outcome_col]\n",
    "Y_control_mean = Y_control.mean()\n",
    "Y_control_std = Y_control.std()\n",
    "e401k[standardised_outcome_col] = (e401k[outcome_col] - Y_control_mean) / Y_control_std\n",
    "e401k_filtered = e401k.loc[(e401k[standardised_outcome_col] > -2) & (e401k[standardised_outcome_col] < +3)]\n",
    "X = jnp.array(e401k_filtered[treatment_col].values)[:, None]\n",
    "Y = jnp.array(e401k_filtered[standardised_outcome_col].values)[:, None]\n",
    "covariate_colnames = [col for col in e401k_filtered.columns if col not in [outcome_col,standardised_outcome_col, treatment_col]]\n",
    "# ['age', 'inc', 'educ', 'fsize', 'marr', 'twoearn', 'db', 'pira', 'hown', 'p401']\n",
    "\n",
    "cont_columns = ['age', 'inc']\n",
    "disc_columns = ['educ', 'fsize', 'marr', 'twoearn', 'db', 'pira', 'hown', 'p401']\n",
    "disc_columns = cont_columns + disc_columns\n",
    "cont_columns = []\n",
    "\n",
    "for col in cont_columns:\n",
    "    mean = e401k_filtered[col].mean()\n",
    "    std = e401k_filtered[col].std()\n",
    "    e401k_filtered[col] = (e401k_filtered[col] - mean) / std\n",
    "\n",
    "Z_cont = jnp.array(e401k_filtered[cont_columns].values).astype(float)\n",
    "Z_cont = None\n",
    "# Z_disc = jnp.array(e401k_filtered[disc_columns].values)\n",
    "Z_disc = jnp.array(e401k_filtered[disc_columns].values)\n",
    "e401k_rescaled = e401k_rescaled[\n",
    "    [standardised_outcome_col, treatment_col] + covariate_colnames\n",
    "]\n",
    "\n",
    "true_ATE = 1000\n",
    "benchmark_flow = FrugalFlowModel(Y=Y, X=X, Z_disc=Z_disc, Z_cont=Z_cont, confounding_copula=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83ee06-37f9-40f6-9183-61a2b7443851",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_flow.train_benchmark_model(\n",
    "    training_seed=jr.PRNGKey(seed),\n",
    "    marginal_hyperparam_dict=marginal_hyperparam_dict,\n",
    "    frugal_hyperparam_dict=hyperparam_dict,\n",
    "    causal_model='location_translation',\n",
    "    causal_model_args={'ate': 0, **causal_margin_hyperparams_dict},\n",
    "    prop_flow_hyperparam_dict=causal_margin_hyperparams_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f27b4b-2005-4491-8d50-1529727b4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_outcome(x, mean, std):\n",
    "    return x * std + mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3fe7f3-e6b2-4942-8912-807a4ad07966",
   "metadata": {},
   "source": [
    "### Unconfounded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf1acd-de2b-4fd9-8ef3-5594a8008a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "e401k_rescaled['age'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a91e4d-4135-49af-a98d-380400b9dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_df = benchmark_flow.generate_samples(\n",
    "    key=jr.PRNGKey(10*seed),\n",
    "    sampling_size=1000,\n",
    "    copula_param=0.,\n",
    "    outcome_causal_model='location_translation',\n",
    "    outcome_causal_args={'ate': true_ATE / Y_control_std},\n",
    "    with_confounding=True\n",
    ")\n",
    "sim_data_df.columns = e401k_rescaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09689d34-9c6e-4813-81ca-13b3f98bca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotted_col = standardised_outcome_col\n",
    "sim_data_df[plotted_col].hist(density=True, alpha=0.5, label='Y from sim_data_df', bins=40)\n",
    "e401k_rescaled[plotted_col].hist(density=True, alpha=0.5, label='Standardized Outcome from e401k_rescaled', bins=40)\n",
    "plt.legend()\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23cd51c-01a5-4981-8a60-2158487f3bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=1.25)\n",
    "fig,ax = plt.subplots(ncols=2,figsize=(18,6))\n",
    "sns.heatmap(e401k_rescaled[[standardised_outcome_col] + covariate_colnames].corr(),ax=ax[0],square=True)\n",
    "ax[0].set_title('Observed e401k Data')\n",
    "sns.heatmap(sim_data_df[[standardised_outcome_col] + covariate_colnames].corr(),ax=ax[1],square=True)\n",
    "ax[1].set_title('Generated e401k Data')\n",
    "# fig.savefig('Lalonde_NSW_0_1000_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cc9a71-7ff9-4521-bb86-9c62bb608329",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch\n",
    "from torch_two_sample import MMDStatistic, EnergyStatistic, FRStatistic, KNNStatistic\n",
    "\n",
    "n_real = e401k_rescaled.shape[0]\n",
    "n_synth = sim_data_df.shape[0]\n",
    "\n",
    "# Convert to torch tensors\n",
    "real_samples_var = torch.tensor(e401k_rescaled.values, dtype=torch.float32)\n",
    "synth_samples_var = torch.tensor(sim_data_df.values, dtype=torch.float32)\n",
    "\n",
    "# Initialize test statistics\n",
    "alphas = [0.1]\n",
    "mmd = MMDStatistic(n_real, n_synth)\n",
    "mmd_matrix = mmd(real_samples_var, synth_samples_var, alphas, ret_matrix=True)[1]\n",
    "print(mmd.pval(mmd_matrix, n_permutations=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a81c5-4848-43f8-8df8-299509b685d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa2724-c8ff-409b-b64b-c8b402356303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16466954-b6d5-4305-9dae-ed74ef11aeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cceb90-7749-484e-9d98-bdca52a41ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39ea61-f6a6-4cb3-894d-536c5c9962af",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.5, 1.0, 2.0]\n",
    "k = 3\n",
    "# cols = ['age', 'black', 'education']\n",
    "cols = [\"age\"]#, \"education\", \"black\", \"hispanic\", \"married\", \"nodegree\"]\n",
    "# cols = covariate_colnames\n",
    "compare_datasets(e401k_rescaled.loc[:, cols].values, sim_data_df.loc[:, cols].values, alphas=alphas, k=3, n_permutations=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
