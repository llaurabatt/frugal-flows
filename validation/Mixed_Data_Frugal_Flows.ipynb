{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f05dc14a-b9f6-4de9-8a36-524db299b21d",
   "metadata": {},
   "source": [
    "# Mixed Data Frugal Flows\n",
    "\n",
    "In this notebook we demonstrate the ability for Frugal Flows to identify Marginal Causal Effects when dealing with a mix of discrete and continous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1628a626-5ea2-4cf5-b80c-2c8876f38ec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (causal_flows.py, line 136)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/micromamba/envs/deep-frugal/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 17\u001b[0;36m\n\u001b[0;31m    from frugal_flows.causal_flows import get_independent_quantiles, train_frugal_flow\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-danielmanela@gmail.com/My Drive/work/deep-copula-frugal/validation/../frugal_flows/causal_flows.py:136\u001b[0;36m\u001b[0m\n\u001b[0;31m    flow_layers=flow_layers\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import jax\n",
    "import jax.random as jr\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from data.create_sim_data import simulate_data\n",
    "from frugal_flows.causal_flows import get_independent_quantiles, train_frugal_flow\n",
    "from frugal_flows.bijections import UnivariateNormalCDF\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6136417-f7d2-4a91-ab9f-4da293e82925",
   "metadata": {},
   "source": [
    "## Checking for the Causal Effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c5e19-b1cb-4a4b-8a77-9b4bbc17afcb",
   "metadata": {},
   "source": [
    "Generating Normalised Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f7442-a2e4-4ea7-a466-d2d387710782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_var(Z, col_idx, inv_cdf):\n",
    "    return inv_cdf(\n",
    "            jax.scipy.special.ndtr(Z[:, col_idx])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e33237-d8fd-4eac-8fd4-3044a75c09f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z[:, [0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a17ed6-2ce2-4743-9ac2-c076778bca4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec11ae74-d510-43bf-9146-c3fb5e326489",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b69630-5b9c-4a01-ab98-1023839a70c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "\n",
    "# marginal_Z = {\n",
    "#     'Z1': ss.norm(loc=0, scale=1),\n",
    "#     'Z2': ss.norm(loc=0, scale=1),\n",
    "#     'Z3': ss.norm(loc=3, scale=5),\n",
    "#     'Z4': ss.norm(loc=-1, scale=2),\n",
    "#     # 'Z5': ss.norm(loc=0, scale=1)\n",
    "# }\n",
    "# corr_matrix = np.array([\n",
    "#     [1, 0.8, 0.6, 0.2, 0.1],\n",
    "#     [0.8, 1, 0.4, 0.2, 0.1],\n",
    "#     [0.6, 0.4, 1, 0.1, 0.1],\n",
    "#     [0.2, 0.2, 0.1, 1, 0.1],\n",
    "#     [0.1, 0.1, 0.1, 0.1, 1]\n",
    "# ])\n",
    "# treatment_type = \"D\"\n",
    "# outcome_type = \"C\"\n",
    "# prop_score_weights = [1, 1, 1, 1]  # Check propscore weights are of same dim as Z\n",
    "# causal_params = [1, 1]\n",
    "# data_xdyc = simulate_data(N, corr_matrix, marginal_Z, prop_score_weights, \"D\", causal_params, \"C\")\n",
    "# df_Z = scipy.stats.zscore(data_xdyc[['Z1', 'Z2', 'Z3', 'Z4']].values)\n",
    "\n",
    "# Y = jnp.array(data_xdyc[['Y']].values)\n",
    "# X = jnp.array(data_xdyc[['X']].values)\n",
    "# Z = jnp.array(df_Z)\n",
    "\n",
    "keys = jr.split(jr.PRNGKey(0), 3)\n",
    "\n",
    "\n",
    "Z = jr.multivariate_normal(\n",
    "    keys[1], \n",
    "    jnp.array([0.,0.,0.,0.,0.]), \n",
    "    jnp.array([\n",
    "        [1, 0.8, 0.6, 0.2, 0.1],\n",
    "        [0.8, 1, 0.4, 0.2, 0.1],\n",
    "        [0.6, 0.4, 1, 0.1, 0.1],\n",
    "        [0.2, 0.2, 0.1, 1, 0.1],\n",
    "        [0.1, 0.1, 0.1, 0.1, 1]\n",
    "    ]), \n",
    "    shape=(N,)\n",
    ")\n",
    "\n",
    "\n",
    "p = 1 / (\n",
    "    1 + jnp.exp(-jnp.sum((Z) * 1 * jnp.ones(shape=(Z.shape[0], Z.shape[1])), axis=1))\n",
    ")\n",
    "X = jr.bernoulli(key=jr.PRNGKey(1), p=p).astype(int)[:, None]\n",
    "Y = (jax.random.normal(keys[2], shape=(N,1)) + X + jnp.expand_dims(Z.sum(1), axis=1))\n",
    "\n",
    "poisson_icdf = lambda x: scipy.stats.poisson.ppf(x, mu=5)\n",
    "gamma_icdf = lambda x: scipy.stats.gamma.ppf(x, a=4)\n",
    "bernoulli_icdf = lambda x: scipy.stats.bernoulli.ppf(x, p=0.3)\n",
    "\n",
    "icdf_transforms = [poisson_icdf]#, bernoulli_icdf]#, gamma_icdf]\n",
    "for i, icdf in enumerate(icdf_transforms):\n",
    "    Z = Z.at[:, i].set(transform_var(Z, i, icdf))\n",
    "\n",
    "data_xdyc = pd.DataFrame(\n",
    "    jnp.concat([Y, X, Z], axis=1),\n",
    "    columns=['Y', 'X'] + [f\"Z{i+1}\" for i in range(Z.shape[1])]\n",
    ")\n",
    "\n",
    "res = get_independent_quantiles(\n",
    "    key = jr.PRNGKey(3),\n",
    "    z_discr=jnp.expand_dims(Z[:, 0],axis=1), #impose discrete\n",
    "    # z_discr=Z[:, 0],\n",
    "    z_cont=Z[:, 1:],\n",
    "    RQS_knots=8,\n",
    "    flow_layers=4,\n",
    "    nn_width=10,\n",
    "    nn_depth=4,\n",
    "    max_epochs = 1000,\n",
    "    max_patience=100,\n",
    "    learning_rate=5e-3,\n",
    "    return_z_cont_flow = True,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d9b10-dfa1-41bc-bd59-57b96cd328dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [f\"U_Z{i}\" for i in range(Z.shape[1])]\n",
    "plot_data = pd.DataFrame(res['u_z_cont'], columns=col_names)\n",
    "plot_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea10e5-051f-48ab-9e3c-aac049f00d61",
   "metadata": {},
   "source": [
    "The correlation matrices have very close to the same entries but the rows and columns are permuted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c06ef3-b8f3-4da1-a6cb-61cded7321be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Corr\")\n",
    "display(jnp.corrcoef(Z.T))\n",
    "print(\"Flow Corr\")\n",
    "display(jnp.corrcoef(jax.scipy.special.ndtri(plot_data.values).T))\n",
    "sns.jointplot(x='U_Z1', y='U_Z2', data=plot_data, kind=\"scatter\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7345eec-873b-4226-8410-48906f067c73",
   "metadata": {},
   "source": [
    "## Check conditional effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c9678-9ee5-43da-aa30-45b30d7ceb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xdyc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e56d7a-803e-487d-b9c6-2e7ad72838af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df_reg = data_xdyc[['Y', 'X']]\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "X_encoded = encoder.fit_transform(data_xdyc[['X']])\n",
    "model = LinearRegression()\n",
    "model.fit(X_encoded, df_reg['Y'])\n",
    "\n",
    "print(f\"Intercept: {model.intercept_}\")\n",
    "print(f\"Coefficients: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febfb413-f207-420b-8033-b599f642daa3",
   "metadata": {},
   "source": [
    "The data is indeed confounded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e8c7f6-a35f-435a-95fe-b077e9d39437",
   "metadata": {},
   "source": [
    "### Training the Frugal FLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32cf366-47e3-4c53-a6cc-015b0c7dc793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_fits(frugal_flow):\n",
    "    causal_margin = frugal_flow.bijection.bijections[-1].bijection.bijections[0]\n",
    "    return {\n",
    "        'ate': causal_margin.ate,\n",
    "        'const': causal_margin.const,\n",
    "        'scale': causal_margin.scale\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba11b9c-085c-46a4-a515-c5948be776a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frugal_flow, losses =  train_frugal_flow(\n",
    "#     key=jr.PRNGKey(1),\n",
    "#     y=jnp.array(Y),\n",
    "#     u_z=res['u_z_cont'],\n",
    "#     RQS_knots=4,\n",
    "#     nn_depth=4,\n",
    "#     nn_width=10,\n",
    "#     flow_layers=1,\n",
    "#     show_progress=True,\n",
    "#     learning_rate=1e-2,\n",
    "#     max_epochs=20000,\n",
    "#     max_patience=100,\n",
    "#     batch_size=100,\n",
    "#     condition=jnp.array(X),\n",
    "#  )\n",
    "\n",
    "frugal_flow, losses = train_frugal_flow(key=jr.PRNGKey(1),\n",
    "    y=Y,\n",
    "    u_z=res['u_z_cont'],\n",
    "    # u_z=res['u_z_cont'],\n",
    "    learning_rate=5e-3,\n",
    "    RQS_knots=8,\n",
    "    nn_depth=4,\n",
    "    nn_width=10,\n",
    "    flow_layers=8,\n",
    "    max_patience=70,\n",
    "    max_epochs=10000,\n",
    "    condition=X\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae174bcb-7ff6-4833-aeda-962636d1aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_fits(frugal_flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad9369-a8a5-4eac-8d1f-5d682c66873b",
   "metadata": {},
   "source": [
    "## Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2714bf1-68c9-463d-bc8c-c365ac202bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = jr.split(jr.PRNGKey(0), 3)\n",
    "frugal_flow_samples_0 = frugal_flow.sample(keys[0], condition=jnp.zeros((5000,1))) #\n",
    "frugal_flow_samples_1 = frugal_flow.sample(keys[1], condition=jnp.ones((5000,1))) #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c04426-192e-4072-84b5-bd6daae2a512",
   "metadata": {},
   "source": [
    "### No correlation between $Y$ and $Z_1$ or $Z_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84712f-f9c0-4e08-84eb-43a8b54376a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frugal_flow_samples_0 = frugal_flow_samples_0.at[:, 1:].set(jax.scipy.special.ndtri(frugal_flow_samples_0[:, 1:]))\n",
    "frugal_flow_samples_1 = frugal_flow_samples_1.at[:, 1:].set(jax.scipy.special.ndtri(frugal_flow_samples_1[:, 1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990409b-dfde-428e-8f9a-09f554746e97",
   "metadata": {},
   "source": [
    "True Correlation Matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a7402-a630-4fd9-b990-52c2b163ab60",
   "metadata": {},
   "source": [
    "Flow outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be76e6a9-673a-4637-b9af-c006f13c322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.corrcoef(frugal_flow_samples_0.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a43c9-2f2c-4487-9745-68b6883f4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.corrcoef(frugal_flow_samples_1.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375d888-f043-4042-9747-b64cd2f70136",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*frugal_flow_samples_0[:,:2].T, label=\"Y-Z1\", s=3)\n",
    "plt.scatter(*frugal_flow_samples_0[:,[0,2]].T, label=\"Y-Z2\", s=3)\n",
    "\n",
    "# plt.scatter(*jax.scipy.special.ndtr(z).T, label=\"target\", s=2)\n",
    "plt.xlabel('u_y')\n",
    "plt.ylabel('u_z1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36541525-ed25-46e2-ba9d-faa6b860336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*frugal_flow_samples_0[:,1:].T, label=\"zero\", s=2)\n",
    "plt.scatter(*jax.scipy.special.ndtri(res['u_z_cont']).T, label=\"one\", s=3)\n",
    "plt.xlabel('u_z1')\n",
    "plt.ylabel('u_z2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b23fc45-3a43-4480-91c8-865ad26d6c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
